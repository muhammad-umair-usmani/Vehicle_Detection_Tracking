{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from ultralytics import YOLO\n",
    "from sort.sort import Sort\n",
    "import imageio\n",
    "import os\n",
    "import pygifsicle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_color_for_id(label):\n",
    "    \"\"\"\n",
    "    Simple function that adds fixed color depending on the id\n",
    "    \"\"\"\n",
    "    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
    "\n",
    "    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "    return tuple(color)\n",
    "# plot_one_box(bboxes, overlayImage, label=label, color=color, line_thickness=line_thickness, bottom_label=bottom_label)\n",
    "def plot_one_box(x, img, color=None, label=None, line_thickness=None, bottom_label=None):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1# line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    tf = max(tl - 1, 1)# font thickness\n",
    "    if label:\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c4 = c1[0] + t_size[0], c1[1] - t_size[1] - 3# filled\n",
    "        cv2.rectangle(img, c1, c4, color, -1, cv2.LINE_AA)\n",
    "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    if bottom_label:\n",
    "        a_size = cv2.getTextSize(bottom_label, 0, fontScale=tl / 4, thickness=tf)[0]\n",
    "        c3 = c1[0] + a_size[0], c2[1] + a_size[1] + 3\n",
    "        cv2.rectangle(img, (c1[0], c2[1]), c3, color, -1, cv2.LINE_AA)\n",
    "        cv2.putText(img, bottom_label, (c1[0], c2[1] + 12), 0, tl / 4, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "\n",
    "def plot_text(up_text,img,c1=(546,40),c2=(550,50)):\n",
    "    tl = 3\n",
    "    tf = max(tl - 1, 1)# font thickness\n",
    "    up_text_size = cv2.getTextSize(up_text, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "    c4 = c1[0] + up_text_size[0], c1[1] - up_text_size[1] - 3# filled\n",
    "    cv2.rectangle(img, c1, c4, (0,0,255), -1, cv2.LINE_AA)\n",
    "    cv2.putText(img, up_text, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(im, target_width = 640):\n",
    "    h,w,_  = im.shape\n",
    "    target_height = int(h / w * target_width)\n",
    "    im = cv2.resize(im , (target_width , target_height), interpolation = cv2.INTER_AREA)  \n",
    "    return im,target_height,target_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyxy_xywh(x1,y1,x2,y2):\n",
    "    w = abs(x2-x1)\n",
    "    h = abs(y2-y1)\n",
    "    x,y = x1+w/2,y1+h/2\n",
    "    return x,y,w,h\n",
    "def xywh_xyxy(x,y,w,h):\n",
    "    x1 = x-w/2\n",
    "    y1 = y-h/2\n",
    "    x2 = x+w/2\n",
    "    y2 = y+h/2\n",
    "    return int(x1),int(y1),int(x2),int(y2)\n",
    "\n",
    "def scale_con(x,y,w,h,old,new):\n",
    "    # old : tuple(height,width)\n",
    "    x = int(x* old[0]/new[0])\n",
    "    y = int(y*old[1]/new[1])\n",
    "    h = int(h*old[0]/new[0])\n",
    "    w = int(w*old[1]/new[1])\n",
    "    return x,y,w,h \n",
    "def isInPolygon(PointF, polygon):\n",
    "    i = 0\n",
    "    c = False\n",
    "    j = len(polygon) - 1\n",
    "    for i in range(len(polygon)):        \n",
    "        if (((polygon[i][1] > PointF[1]) != (polygon[j][1] > PointF[1])) and \n",
    "        (PointF[0] < (polygon[j][0] - polygon[i][0]) * (PointF[1] - polygon[i][1]) / (polygon[j][1] - polygon[i][1]) + polygon[i][0])):\n",
    "            c = not(c)\n",
    "        j = i\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model \n",
    "model = YOLO(\"./runs/detect/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracker Initialization\n",
    "sort_tracker = Sort(max_age=20,\n",
    "                   min_hits=5,\n",
    "                   iou_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video Visualization\n",
    "# press y to quit the video\n",
    "cap = cv2.VideoCapture(\"./road_vehicle.mp4\")\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# Video writer\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output = cv2.VideoWriter('processed_road_vehicle_counted.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "print(frame_width,frame_height)\n",
    "\n",
    "# polygons for counting upside and downside vehicles\n",
    "up_polylines = np.array([[390,350],[319,382],[585,428],[599,368]])\n",
    "down_polylines = np.array([[694,444],[720,534],[1105,465],[991,404]])\n",
    "up_vehicles = []\n",
    "down_vehicles = []\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        img,res_height,res_width = resize_img(frame)\n",
    "        \n",
    "        cv2.polylines(frame, [up_polylines], True, (0,0,255), 2)\n",
    "        cv2.polylines(frame, [down_polylines], True, (0,0,255), 2)\n",
    "        plot_text(\"UP Vehicles : {}\".format(len(up_vehicles)),frame,(546,40),(550,50))\n",
    "        plot_text(\"Down Vehicles : {}\".format(len(down_vehicles)),frame,(546,75),(600,50))\n",
    "        result = model.predict(img)[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        bboxes = np.array(result.boxes.xywh)\n",
    "        mapped_bboxes = [[0]]*len(bboxes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for ind,bbox in enumerate(bboxes):\n",
    "            x,y,w,h = scale_con(bbox[0],bbox[1],bbox[2],bbox[3],(frame_height,frame_width),(res_height,res_width))\n",
    "            x1,y1,x2,y2 = xywh_xyxy(x,y,w,h)\n",
    "            \n",
    "            mapped_bboxes[ind] = [x1,y1,x2,y2]\n",
    "        # tracker updations\n",
    "        outputs = sort_tracker.update(np.array(mapped_bboxes))\n",
    "        \n",
    "        for box in outputs:\n",
    "            x1,y1,x2,y2,tid, = box\n",
    "            plot_one_box(x=(x1,y1,x2,y2),img=frame,color=compute_color_for_id(int(tid))\n",
    "                         ,label=str(int(tid)),line_thickness=1)\n",
    "            x,y,w,h = xyxy_xywh(x1,y1,x2,y2)\n",
    "            \n",
    "            # check bbox belong to wich polygon to add counter in vehicle passing\n",
    "            \n",
    "            if isInPolygon((x,y),up_polylines):\n",
    "                if tid not in up_vehicles:\n",
    "                    up_vehicles.append(tid)\n",
    "            elif isInPolygon((x,y),down_polylines):\n",
    "                if tid not in down_vehicles:\n",
    "                    down_vehicles.append(tid)   \n",
    "            \n",
    "            \n",
    "        output.write(frame)\n",
    "#         cv2.imshow('Frame',frame)\n",
    "#         k =cv2.waitKey(0) & 0xFF\n",
    "#         #press y to exit\n",
    "#         if k==121:\n",
    "#             break\n",
    "#         else:\n",
    "#             pass\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 720 25.0\n",
      "640 360 25.0\n"
     ]
    }
   ],
   "source": [
    "# writing processed and unprocessed video file side by side\n",
    "cap1 = cv2.VideoCapture(\"./road_vehicle.mp4\")\n",
    "cap2 = cv2.VideoCapture(\"./processed_road_vehicle_counted.mp4\")\n",
    "frame_width = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "target_width = frame_width//2\n",
    "target_height = frame_height//2\n",
    "fps = cap1.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Video writer\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output = cv2.VideoWriter('joined_video.mp4', fourcc, fps, (frame_width, target_height))\n",
    "\n",
    "\n",
    "# target_frames = 800\n",
    "print(frame_width,frame_height,fps)\n",
    "print(target_width,target_height,fps)\n",
    "while(cap1.isOpened()):\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "    if ret1 == True and ret2 == True :\n",
    "        res_frame1 = cv2.resize(frame1 , (target_width , target_height), interpolation = cv2.INTER_AREA)  \n",
    "        res_frame2 = cv2.resize(frame2 , (target_width , target_height), interpolation = cv2.INTER_AREA) \n",
    "        concat_frame = np.concatenate((res_frame1, res_frame2), axis=1)\n",
    "        \n",
    "        output.write(concat_frame)\n",
    "#         cv2.imshow('Frame',concat_frame)\n",
    "#         k =cv2.waitKey(0) & 0xFF\n",
    "#         #press y to exit\n",
    "#         if k==121:\n",
    "#             break\n",
    "#         else:\n",
    "#             pass\n",
    "    else:\n",
    "        break\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import moviepy.editor as mp\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_video_to_gif(input_video_path, output_gif_path, fps=25):\n",
    "    video_clip = mp.VideoFileClip(input_video_path)\n",
    "    video_clip.write_gif(output_gif_path, fps=fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file ./joined_video.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    }
   ],
   "source": [
    "video_file = \"./joined_video.mp4\"\n",
    "output_gif_file = \"./joined_video.gif\"\n",
    "convert_video_to_gif(video_file, output_gif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A                                                         \n",
      "\n",
      "t:   7%|â–‹         | 30/459 [5:23:11<02:10,  3.29it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file ./clipped_joined_video.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_half_video_to_gif(input_video_path, output_gif_path):\n",
    "    # Load the video clip\n",
    "    video_clip = VideoFileClip(input_video_path)\n",
    "\n",
    "    # Get the duration of the video\n",
    "    total_duration = video_clip.duration\n",
    "\n",
    "    # Set the end time for the first half\n",
    "    end_time = total_duration / 2\n",
    "#     print(end_time,type(end_time))\n",
    "\n",
    "    # Trim the video to the first half\n",
    "    trimmed_clip = video_clip.subclip(0, 10.0)\n",
    "\n",
    "    # Write the trimmed video as a GIF\n",
    "    trimmed_clip.write_gif(output_gif_path)\n",
    "\n",
    "video_file = \"./joined_video.mp4\"\n",
    "output_gif_file = \"./clipped_joined_video.gif\"\n",
    "convert_half_video_to_gif(video_file, output_gif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
